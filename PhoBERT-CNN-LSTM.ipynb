{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5332200,"sourceType":"datasetVersion","datasetId":3097079},{"sourceId":5368578,"sourceType":"datasetVersion","datasetId":3107553},{"sourceId":5377989,"sourceType":"datasetVersion","datasetId":3119418},{"sourceId":5418960,"sourceType":"datasetVersion","datasetId":3131743}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install py_vncorenlp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T03:17:15.096130Z","iopub.execute_input":"2026-01-17T03:17:15.096975Z","iopub.status.idle":"2026-01-17T03:17:18.087046Z","shell.execute_reply.started":"2026-01-17T03:17:15.096935Z","shell.execute_reply":"2026-01-17T03:17:18.086311Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: py_vncorenlp in /usr/local/lib/python3.12/dist-packages (0.1.4)\nRequirement already satisfied: pyjnius in /usr/local/lib/python3.12/dist-packages (from py_vncorenlp) (1.7.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\n# Create the directory\nos.makedirs('ngcanh/finetunephobert/models/wordsegmenter', exist_ok=True)\n\n# 1. Download the JAR file (Renaming it to 1.2 to satisfy the library's requirement)\n!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar -O ngcanh/finetunephobert/VnCoreNLP-1.2.jar\n\n# 2. Download the Word Segmentation models\n!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab -O ngcanh/finetunephobert/models/wordsegmenter/vi-vocab\n!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr -O ngcanh/finetunephobert/models/wordsegmenter/wordsegmenter.rdr\n\nprint(\"Setup complete. Files are ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T03:17:18.088548Z","iopub.execute_input":"2026-01-17T03:17:18.088867Z","iopub.status.idle":"2026-01-17T03:17:18.701209Z","shell.execute_reply.started":"2026-01-17T03:17:18.088838Z","shell.execute_reply":"2026-01-17T03:17:18.700461Z"}},"outputs":[{"name":"stdout","text":"--2026-01-17 03:17:18--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 27412575 (26M) [application/octet-stream]\nSaving to: ‚Äòngcanh/finetunephobert/VnCoreNLP-1.2.jar‚Äô\n\nngcanh/finetunephob 100%[===================>]  26.14M  --.-KB/s    in 0.1s    \n\n2026-01-17 03:17:18 (249 MB/s) - ‚Äòngcanh/finetunephobert/VnCoreNLP-1.2.jar‚Äô saved [27412575/27412575]\n\n--2026-01-17 03:17:18--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 526544 (514K) [application/octet-stream]\nSaving to: ‚Äòngcanh/finetunephobert/models/wordsegmenter/vi-vocab‚Äô\n\nngcanh/finetunephob 100%[===================>] 514.20K  --.-KB/s    in 0.02s   \n\n2026-01-17 03:17:18 (21.6 MB/s) - ‚Äòngcanh/finetunephobert/models/wordsegmenter/vi-vocab‚Äô saved [526544/526544]\n\n--2026-01-17 03:17:18--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 128508 (125K) [text/plain]\nSaving to: ‚Äòngcanh/finetunephobert/models/wordsegmenter/wordsegmenter.rdr‚Äô\n\nngcanh/finetunephob 100%[===================>] 125.50K  --.-KB/s    in 0.01s   \n\n2026-01-17 03:17:18 (8.53 MB/s) - ‚Äòngcanh/finetunephobert/models/wordsegmenter/wordsegmenter.rdr‚Äô saved [128508/128508]\n\nSetup complete. Files are ready.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import py_vncorenlp\nimport os\n\n# Manual setup of paths (Run only if needed)\nif not os.path.exists('ngcanh/finetunephobert/models/wordsegmenter'):\n    os.makedirs('ngcanh/finetunephobert/models/wordsegmenter', exist_ok=True)\n    !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar -O ngcanh/finetunephobert/VnCoreNLP-1.2.jar\n    !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab -O ngcanh/finetunephobert/models/wordsegmenter/vi-vocab\n    !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr -O ngcanh/finetunephobert/models/wordsegmenter/wordsegmenter.rdr\n\n# --- SAFE INITIALIZATION ---\n# Check if 'rdrsegmenter' already exists. If yes, skip initialization to avoid JVM crash.\nif 'rdrsegmenter' not in globals():\n    try:\n        rdrsegmenter = py_vncorenlp.VnCoreNLP(\n            save_dir='ngcanh/finetunephobert', \n            annotators=[\"wseg\"]\n        )\n        print(\"Model loaded successfully.\")\n    except ValueError as e:\n        # If the JVM is already running but the variable is lost (rare), we can't reload.\n        print(f\"Error: {e}\")\n        print(\"Please Restart Session (Run -> Restart Session) to recover.\")\nelse:\n    print(\"Model is already loaded. Skipping initialization to prevent JVM crash.\")\n\n# Helper function\ndef segment_text(text):\n    if not isinstance(text, str) or not text:\n        return \"\"\n    try:\n        sentences = rdrsegmenter.word_segment(text)\n        return \" \".join(sentences)\n    except:\n        return text\n\n# Test\nprint(segment_text(\"ƒê·∫°i h·ªçc B√°ch Khoa H√† N·ªôi\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T03:17:18.702527Z","iopub.execute_input":"2026-01-17T03:17:18.702838Z","iopub.status.idle":"2026-01-17T03:17:18.715365Z","shell.execute_reply.started":"2026-01-17T03:17:18.702799Z","shell.execute_reply":"2026-01-17T03:17:18.714705Z"}},"outputs":[{"name":"stdout","text":"Error: VM is already running, can't set classpath/options; VM started at  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n    ColabKernelApp.launch_instance()\n  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n    res = shell.run_cell(\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n    result = self._run_cell(\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_55/1671981362.py\", line 15, in <cell line: 0>\n    rdrsegmenter = py_vncorenlp.VnCoreNLP(\n  File \"/usr/local/lib/python3.12/dist-packages/py_vncorenlp/vncorenlp.py\", line 53, in __init__\n    from jnius import autoclass\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"/usr/local/lib/python3.12/dist-packages/jnius/__init__.py\", line 45, in <module>\n    from .reflect import *  # noqa\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"/usr/local/lib/python3.12/dist-packages/jnius/reflect.py\", line 19, in <module>\n    class Class(JavaClass, metaclass=MetaJavaClass):\n\nPlease Restart Session (Run -> Restart Session) to recover.\nƒê·∫°i h·ªçc B√°ch Khoa H√† N·ªôi\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install \"protobuf<4.0.0\" --force-reinstall","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T03:17:18.717557Z","iopub.execute_input":"2026-01-17T03:17:18.717854Z","iopub.status.idle":"2026-01-17T03:17:22.586193Z","shell.execute_reply.started":"2026-01-17T03:17:18.717832Z","shell.execute_reply":"2026-01-17T03:17:22.585467Z"}},"outputs":[{"name":"stdout","text":"Collecting protobuf<4.0.0\n  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\nDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 5.29.5\n    Uninstalling protobuf-5.29.5:\n      Successfully uninstalled protobuf-5.29.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\na2a-sdk 0.3.22 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.20.1 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-3.20.3\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install --upgrade ipywidgets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T03:17:22.587420Z","iopub.execute_input":"2026-01-17T03:17:22.587720Z","iopub.status.idle":"2026-01-17T03:17:26.109064Z","shell.execute_reply.started":"2026-01-17T03:17:22.587682Z","shell.execute_reply":"2026-01-17T03:17:26.108338Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (8.1.5)\nCollecting ipywidgets\n  Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (0.2.3)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (4.0.15)\nRequirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.0.15)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (75.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\nRequirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\nRequirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.14)\nDownloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: ipywidgets\n  Attempting uninstall: ipywidgets\n    Found existing installation: ipywidgets 8.1.5\n    Uninstalling ipywidgets-8.1.5:\n      Successfully uninstalled ipywidgets-8.1.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ipywidgets-8.1.8\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install -U sentence-transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T03:17:26.110285Z","iopub.execute_input":"2026-01-17T03:17:26.110544Z","iopub.status.idle":"2026-01-17T03:17:30.190911Z","shell.execute_reply.started":"2026-01-17T03:17:26.110515Z","shell.execute_reply":"2026-01-17T03:17:30.190225Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\nCollecting sentence-transformers\n  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (26.0rc2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.1rc0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\nDownloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\n  Attempting uninstall: sentence-transformers\n    Found existing installation: sentence-transformers 5.1.1\n    Uninstalling sentence-transformers-5.1.1:\n      Successfully uninstalled sentence-transformers-5.1.1\nSuccessfully installed sentence-transformers-5.2.0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import sys\n\nsys.path.append(\"../input/sentence-transformers\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T03:17:30.191996Z","iopub.execute_input":"2026-01-17T03:17:30.192291Z","iopub.status.idle":"2026-01-17T03:17:30.196076Z","shell.execute_reply.started":"2026-01-17T03:17:30.192248Z","shell.execute_reply":"2026-01-17T03:17:30.195402Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import transformers\n# import sentence_transformers\n\nprint(\"Transformers:\", transformers.__version__)\n# print(\"Sentence Transformers:\", sentence_transformers.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T03:17:30.196940Z","iopub.execute_input":"2026-01-17T03:17:30.197426Z","iopub.status.idle":"2026-01-17T03:17:35.730515Z","shell.execute_reply.started":"2026-01-17T03:17:30.197404Z","shell.execute_reply":"2026-01-17T03:17:35.729690Z"}},"outputs":[{"name":"stdout","text":"Transformers: 4.57.1\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import warnings\nfrom transformers import logging\n\nwarnings.filterwarnings('ignore')\nlogging.set_verbosity_error()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T03:17:35.732362Z","iopub.execute_input":"2026-01-17T03:17:35.732717Z","iopub.status.idle":"2026-01-17T03:17:35.736690Z","shell.execute_reply.started":"2026-01-17T03:17:35.732692Z","shell.execute_reply":"2026-01-17T03:17:35.735981Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import random, os\nimport numpy as np\nimport torch\n\n\ndef seed_everything(seed: int):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \nseed_everything(42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T03:17:35.739048Z","iopub.execute_input":"2026-01-17T03:17:35.739296Z","iopub.status.idle":"2026-01-17T03:17:35.759352Z","shell.execute_reply.started":"2026-01-17T03:17:35.739276Z","shell.execute_reply":"2026-01-17T03:17:35.758875Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from torch import nn\nfrom transformers import AutoModel, BertModel\nimport torch.nn.functional as F\n\n\nclass ViSpam_Classifier_PhoBertCNN(nn.Module):\n    def __init__(self, task, freeze_bert=False, drop=0.3):\n        super(ViSpam_Classifier_PhoBertCNN, self).__init__()\n        \n        self.bert = AutoModel.from_pretrained('vinai/phobert-base-v2')\n        self.hidden_size = 768\n        \n        self.model_name = 'PhoBert-CNN'\n        self.task = task\n        self.num_classes = 2 if task == 1 else 3\n        self.desc_size = 768  # Size of the description vector\n        \n        # CNN Layers\n        self.conv1 = nn.Conv1d(in_channels=self.hidden_size, out_channels=100, kernel_size=2)\n        self.conv2 = nn.Conv1d(in_channels=self.hidden_size, out_channels=100, kernel_size=3)\n        self.conv3 = nn.Conv1d(in_channels=self.hidden_size, out_channels=100, kernel_size=4)\n        \n        self.dropout = nn.Dropout(drop)\n        \n        # --- KEY CHANGE 1: Increase input size of Fully Connected layer ---\n        # CNN output (100*3) + Description Vector (768) = 1068\n        self.fc = nn.Linear(100 * 3 + self.desc_size, self.num_classes)\n        \n    def forward(self, input_ids, attention_mask, description):\n        # 1. BERT Pass\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        last_hidden_state = outputs.last_hidden_state\n        \n        # 2. CNN Pass\n        x = last_hidden_state.permute(0, 2, 1) # (batch, hidden, seq)\n        \n        x1 = F.relu(self.conv1(x))\n        x1 = F.max_pool1d(x1, x1.shape[2]).squeeze(2)\n        \n        x2 = F.relu(self.conv2(x))\n        x2 = F.max_pool1d(x2, x2.shape[2]).squeeze(2)\n        \n        x3 = F.relu(self.conv3(x))\n        x3 = F.max_pool1d(x3, x3.shape[2]).squeeze(2)\n        \n        cnn_output = torch.cat((x1, x2, x3), dim=1) # Size: 300\n        \n        # --- KEY CHANGE 2: Concatenate Description ---\n        # Combine CNN features with Description features\n        combined_features = torch.cat((cnn_output, description), dim=1) # Size: 1068\n        \n        x_cat = self.dropout(combined_features)\n        logits = self.fc(x_cat)\n        \n        return logits\n\n\n\nclass ViSpam_Classifier_PhoBertBiLSTM(nn.Module):\n    def __init__(self, task, freeze_bert=False, drop=0.3, lstm_hidden_size=256):\n        super(ViSpam_Classifier_PhoBertBiLSTM, self).__init__()\n        \n        # 1. Backbone: PhoBERT\n        self.bert = AutoModel.from_pretrained('vinai/phobert-base')\n        \n        # C·∫•u h√¨nh Task\n        self.model_name = 'PhoBert-BiLSTM'\n        self.task = task\n        self.num_classes = 2 if task == 1 else 3\n        self.desc_size = 768  # K√≠ch th∆∞·ªõc vector description\n        \n        # T√πy ch·ªçn ƒë√≥ng bƒÉng PhoBERT (th∆∞·ªùng kh√¥ng n√™n ƒë√≥ng bƒÉng ƒë·ªÉ fine-tune t·ªët h∆°n)\n        if freeze_bert:\n            for param in self.bert.parameters():\n                param.requires_grad = False\n                \n        # 2. Bi-LSTM Layer\n        # input_size=768 (output c·ªßa PhoBERT)\n        # bidirectional=True -> output s·∫Ω c√≥ k√≠ch th∆∞·ªõc hidden_size * 2\n        self.lstm = nn.LSTM(\n            input_size=768, \n            hidden_size=lstm_hidden_size, \n            num_layers=1, \n            batch_first=True, \n            bidirectional=True\n        )\n        \n        self.dropout = nn.Dropout(drop)\n        \n        # 3. Fully Connected Layer\n        # Input size = (LSTM_Hidden * 2) + Description_Size\n        # V√≠ d·ª•: (256 * 2) + 768 = 512 + 768 = 1280\n        fc_input_size = (lstm_hidden_size * 2) + self.desc_size\n        self.fc = nn.Linear(fc_input_size, self.num_classes)\n        \n    def forward(self, input_ids, attention_mask, description):\n        # --- B∆∞·ªõc 1: PhoBERT ---\n        # outputs.last_hidden_state shape: [Batch_Size, Seq_Len, 768]\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        last_hidden_state = outputs.last_hidden_state\n        \n        # --- B∆∞·ªõc 2: Bi-LSTM ---\n        # lstm_out shape: [Batch_Size, Seq_Len, LSTM_Hidden * 2]\n        # _ (hidden states): kh√¥ng c·∫ßn d√πng trong tr∆∞·ªùng h·ª£p n√†y\n        lstm_out, _ = self.lstm(last_hidden_state)\n        \n        # --- B∆∞·ªõc 3: Pooling (R√∫t g·ªçn chu·ªói) ---\n        # C√°ch 1: L·∫•y vector t·∫°i b∆∞·ªõc th·ªùi gian cu·ªëi c√πng (Last hidden state)\n        # C√°ch 2: Mean Pooling (Trung b√¨nh c·ªông t·∫•t c·∫£ c√°c b∆∞·ªõc th·ªùi gian) -> ·ªîn ƒë·ªãnh h∆°n cho classification\n        # Shape sau pooling: [Batch_Size, LSTM_Hidden * 2]\n        avg_pool = torch.mean(lstm_out, dim=1)\n        \n        # --- B∆∞·ªõc 4: K·∫øt h·ª£p v·ªõi Description ---\n        # N·ªëi vector ng·ªØ c·∫£nh (t·ª´ LSTM) v·ªõi vector m√¥ t·∫£ (Description)\n        # Shape: [Batch_Size, 1280]\n        combined_features = torch.cat((avg_pool, description), dim=1)\n        \n        # --- B∆∞·ªõc 5: Ph√¢n lo·∫°i ---\n        x = self.dropout(combined_features)\n        logits = self.fc(x)\n        \n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T03:17:35.760059Z","iopub.execute_input":"2026-01-17T03:17:35.760420Z"}},"outputs":[{"name":"stderr","text":"2026-01-17 03:17:43.402919: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768619863.578032      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768619863.629512      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768619864.052734      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768619864.052784      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768619864.052787      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768619864.052789      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import datasets\nimport pandas as pd\nfrom ast import literal_eval\ndatasets.disable_caching()\n\ndata_dir = '/kaggle/input/vispamdataset-v2/preprocessed/'\n\ndef load_data(data_dir):\n    train_df = pd.read_csv(data_dir + 'train.csv', converters={'categories': literal_eval})\n    dev_df = pd.read_csv(data_dir + 'dev.csv', converters={'categories': literal_eval})\n    test_df = pd.read_csv(data_dir + 'test.csv', converters={'categories': literal_eval})\n    \n    train_dataset = datasets.Dataset.from_dict(train_df)\n    dev_dataset = datasets.Dataset.from_dict(dev_df)\n    test_dataset = datasets.Dataset.from_dict(test_df)\n    dataset_dict = datasets.DatasetDict({'train': train_dataset, 'dev': dev_dataset, 'test': test_dataset})\n    \n    return dataset_dict\n\nvispam_datasets = load_data(data_dir)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nclass EarlyStopping:\n    \n    def __init__(self, patience=5, verbose=True, delta=0, path='checkpoint.pth'):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.inf \n        # -----------------------------------------------\n        self.delta = delta\n        self.path = path\n        \n    def __call__(self, val_loss, model):\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            \n            if self.verbose:\n                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            \n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n            \n    def save_checkpoint(self, val_loss, model):\n        if self.verbose:\n            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n            \n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport gc\nimport json\nimport torch\nfrom torch import nn\nimport numpy as np\nfrom scipy import interpolate\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot, plot\n\n\nimport os\nimport gc\nimport json\nimport torch\nfrom torch import nn\nimport numpy as np\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\n\n# 1. C·∫≠p nh·∫≠t h√†m Train Step\ndef train_step(model, criterion, optimizer, train_dataloader, task):\n    model.train()\n    losses = []\n    correct = 0\n    \n    trues = []\n    predicts = []\n\n    # FIX: Lu√¥n d√πng 'label' v√¨ DataLoader Task 2 ƒë√£ chu·∫©n h√≥a t√™n c·ªôt\n    label_column = 'label' \n    \n    for data in tqdm(train_dataloader, desc=\"Training\", leave=False):\n        input_ids = data['input_ids'].to(device)\n        attention_mask = data['attention_mask'].to(device)\n        \n        # Ch·ªçn description theo task\n        if task == 1:\n            description = data['encoded_description_1'].to(device)\n        else:\n            description = data['encoded_description_2'].to(device)\n            \n        labels = data[label_column].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, description=description)\n\n        loss = criterion(outputs, labels)\n        pred = torch.max(outputs, dim=1)[1]\n\n        correct += torch.sum(pred == labels)\n        losses.append(loss.item())\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        lr_scheduler.step()\n        \n        trues.extend(labels.cpu().detach().numpy())\n        predicts.extend(pred.cpu().detach().numpy())\n\n    accuracy = correct.double().cpu().data.numpy()/len(train_dataloader.dataset)\n    loss = np.mean(losses)\n\n    return accuracy, f1_score(trues, predicts, average='macro'), loss\n\n# 2. C·∫≠p nh·∫≠t h√†m Validation Step\ndef validation_step(model, criterion, dataloader, task):\n    model.eval()\n    losses = []\n    correct = 0\n    \n    trues = []\n    predicts = []\n    \n    # FIX: Lu√¥n d√πng 'label'\n    label_column = 'label'\n    \n    with torch.no_grad():\n        for data in dataloader:\n            input_ids = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            \n            if task == 1:\n                description = data['encoded_description_1'].to(device)\n            else:\n                description = data['encoded_description_2'].to(device)\n                \n            labels = data[label_column].to(device)\n            \n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, description=description)\n            pred = torch.max(outputs, dim=1)[1]\n            \n            loss = criterion(outputs, labels)\n            correct += torch.sum(pred == labels)\n            losses.append(loss.item())\n            \n            trues.extend(labels.cpu().detach().numpy())\n            predicts.extend(pred.cpu().detach().numpy())\n            \n    accuracy = correct.double().cpu().data.numpy()/len(dataloader.dataset)\n    loss = np.mean(losses)\n\n    return accuracy, f1_score(trues, predicts, average='macro'), loss\n\n# 3. H√†m Train Loop (Gi·ªØ nguy√™n logic, g·ªçi l·∫°i 2 h√†m tr√™n)\ndef train(model, criterion, optimizer, train_dataloader, val_dataloader, epochs, early_stopping, task):\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    Path(model.model_name).mkdir(parents=True, exist_ok=True)\n    \n    checkpoint_path = os.path.join(model.model_name, f\"{model.model_name}_checkpoint_({task}).pth\")\n    best_model_path = os.path.join(model.model_name, f\"{model.model_name}_best_model_({task}).pth\")\n    last_model_path = os.path.join(model.model_name, f\"{model.model_name}_last_model_({task}).pth\")\n    \n    if early_stopping:\n        early_stopping.path = checkpoint_path\n    \n    best_f1 = 0\n    history = {'train_acc': [], 'train_loss': [], 'val_acc': [], 'val_loss': []}\n\n    print(f\"üöÄ Start Training Task {task}...\")\n\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n        print(\"-\" * 50)\n        \n        train_accuracy, train_f1, train_loss = train_step(model, criterion, optimizer, train_dataloader, task)\n        val_accuracy, val_f1, val_loss = validation_step(model, criterion, val_dataloader, task)\n        \n        history['train_acc'].append(train_accuracy)\n        history['train_loss'].append(train_loss)\n        history['val_acc'].append(val_accuracy)\n        history['val_loss'].append(val_loss)\n        \n        print(f\"Train Loss: {train_loss:.4f} | Train F1: {train_f1:.4f} | Train Acc: {train_accuracy:.4f}\")\n        print(f\"Valid Loss: {val_loss:.4f} | Valid F1: {val_f1:.4f} | Valid Acc: {val_accuracy:.4f}\")\n        \n        if val_f1 > best_f1:\n            print(f\"üî• New Best F1! ({best_f1:.4f} --> {val_f1:.4f}). Saving model...\")\n            torch.save(model.state_dict(), best_model_path)\n            best_f1 = val_f1\n        \n        torch.save(model.state_dict(), last_model_path)\n            \n        if early_stopping:\n            early_stopping(val_loss, model)\n            if early_stopping.early_stop:\n                print(\"üõë Early stopping triggered.\")\n                break\n    \n    history_path = os.path.join(model.model_name, f\"{model.model_name}_history_({task}).json\")\n    with open(history_path, 'w') as f:\n        json.dump(history, f)\n        \n    if os.path.exists(best_model_path):\n        print(\"üì• Reloading best model weights for evaluation...\")\n        model.load_state_dict(torch.load(best_model_path))\n    else:\n        print(\"‚ö†Ô∏è Warning: No best model found, using last epoch weights.\")\n\n    return history\n\nprint(\"‚úÖ ƒê√£ c·∫≠p nh·∫≠t xong c√°c h√†m training!\")\nimport torch.nn.functional as F\n\ndef test(model, dataloader, task, threshold=None):\n    model.eval()\n    predicts = []\n    predict_probs = []\n    true_labels = []\n    \n    label_column = 'label' if task == 1 else 'spam_label'\n\n    for data in tqdm(dataloader):\n        input_ids = data['input_ids'].to(device)\n        attention_mask = data['attention_mask'].to(device)\n        description = data[f'encoded_description_{task}'].to(device)\n        labels = data[label_column].to(device)\n        \n        with torch.no_grad():\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, description=description)\n            probs = F.softmax(outputs, dim=1)\n            if task == 1 and threshold is not None:\n                pred = (probs[:, 1] >= threshold).long()\n            else:\n                pred = torch.max(outputs, dim=1)[1]\n        predicts.extend(pred.cpu().data.numpy())\n        predict_probs.extend(outputs.cpu().data.numpy())\n        true_labels.extend(labels.cpu().data.numpy())\n        \n    return true_labels, predicts\n\n\ndef evaluate(true_labels, predicts):\n    test_accuracy = accuracy_score(true_labels, predicts)\n    test_precision = precision_score(true_labels, predicts, average='macro')\n    test_recall = recall_score(true_labels, predicts, average='macro')\n    test_f1 = f1_score(true_labels, predicts, average='macro')\n    test_cm = confusion_matrix(true_labels, predicts)\n    \n    print(\"Accuracy: {:.4f}\".format(test_accuracy))\n    print(\"Precision: {:.4f}\".format(test_precision))\n    print(\"Recall: {:.4f}\".format(test_recall))\n    print(\"F1-score: {:.4f}\".format(test_f1))\n    print(\"Confusion matrix:\\n\", test_cm)\n    print(classification_report(true_labels, predicts, digits=4))\n    \n    return test_cm\n\n\ndef save_visualization_history(history, model_name, task):\n    if len(history['train_loss']) <= 1:\n        return False\n    \n    colors = plt.get_cmap('tab10').colors\n    \n    epochs = np.arange(1, len(history['train_loss']) + 1)\n    xnew = np.linspace(epochs[0], epochs[-1], 300)\n    \n    train_loss_smooth = interpolate.interp1d(epochs, history['train_loss'], kind='linear')(xnew)\n    val_loss_smooth = interpolate.interp1d(epochs, history['val_loss'], kind='linear')(xnew)\n    \n    fig, ax = plt.subplots()\n    ax.plot(xnew, train_loss_smooth, color=colors[0], linewidth=3, label='Training Loss')\n    ax.plot(xnew, val_loss_smooth, color=colors[1], linewidth=3, label='Validation Loss')\n    ax.set_title('Training and Validation Loss', fontsize=12)\n    ax.set_xlabel('Epoch', fontsize=10, labelpad=10)\n    ax.set_ylabel('Loss', fontsize=10, labelpad=10)\n    ax.tick_params(axis='both', which='both', length=0)\n    ax.grid(axis='y')\n    for pos in ['right', 'top', 'left', 'bottom']:\n        ax.spines[pos].set_visible(False)\n    ax.legend(loc='center left', bbox_to_anchor=(1.05, 0.5), frameon=False, prop={'size': 10})\n    file_name = os.path.join(model_name, f\"{model_name}_loss_visualization_({task}).png\")\n    fig.savefig(file_name, dpi=300, bbox_inches='tight')\n    plt.close(fig)\n    \n    train_acc_smooth = interpolate.interp1d(epochs, history['train_acc'], kind='linear')(xnew)\n    val_acc_smooth = interpolate.interp1d(epochs, history['val_acc'], kind='linear')(xnew)\n\n    fig, ax = plt.subplots()\n    ax.plot(xnew, train_acc_smooth, color=colors[2], linewidth=3, label='Training Accuracy')\n    ax.plot(xnew, val_acc_smooth, color=colors[4], linewidth=3, label='Validation Accuracy')\n    ax.set_title('Training and Validation Accuracy', fontsize=12)\n    ax.set_xlabel('Epoch', fontsize=10, labelpad=10)\n    ax.set_ylabel('Accuracy', fontsize=10, labelpad=10)\n    ax.tick_params(axis='both', which='both', length=0)\n    ax.grid(axis='y')\n    for pos in ['right', 'top', 'left', 'bottom']:\n        ax.spines[pos].set_visible(False)\n    ax.legend(loc='center left', bbox_to_anchor=(1.05, 0.5), frameon=False, prop={'size': 10})\n    file_name = os.path.join(model_name, f\"{model_name}_accuracy_visualization_({task}).png\")\n    fig.savefig(file_name, dpi=300, bbox_inches='tight')\n    plt.close(fig)\n\n\ndef plotting_history(history):\n    assert len(history['train_loss']) == len(history['val_loss'])\n    assert len(history['train_acc']) == len(history['val_acc'])\n    \n    fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Loss\", \"Accuracy\"), shared_yaxes=False, shared_xaxes=False, vertical_spacing=0.1, horizontal_spacing=0.05)\n    \n    num_epochs = len(history['train_loss'])\n    epoch_labels = list(range(1, num_epochs+1))\n    \n    fig.add_trace(go.Scatter(x=epoch_labels, y=history['train_loss'], name='train_loss', legendgroup='1'), row=1, col=1)\n    fig.add_trace(go.Scatter(x=epoch_labels, y=history['val_loss'], name='val_loss', legendgroup='1'), row=1, col=1)\n    fig.add_trace(go.Scatter(x=epoch_labels, y=history['train_acc'], name='train_accuracy', legendgroup='2'), row=1, col=2)\n    fig.add_trace(go.Scatter(x=epoch_labels, y=history['val_acc'], name='val_accuracy', legendgroup='2'), row=1, col=2)\n    \n    fig.update_layout(legend=dict(orientation=\"h\", xanchor=\"center\", x=0.5), showlegend=True)\n    fig.show()\n    \n\ndef plotting_confusion_matrix(confusion_matrix, task):\n    if task == 1:\n        labels = ['no-spam', 'spam']\n        font_size = 30\n    elif  task == 2:\n        labels = ['spam-1', 'spam-2', 'spam-3']\n        font_size = 22\n    else:\n        labels = ['no-spam', 'spam-1', 'spam-2', 'spam-3']\n        font_size = 22\n    plt.figure(dpi=100)\n    df_cm = pd.DataFrame(confusion_matrix, index=labels, columns=labels)\n    sns.heatmap(df_cm, annot=True, cmap=\"Greys\", fmt=\"g\", cbar=True, annot_kws={\"size\": font_size})\n    plt.show()\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.utils import class_weight\n\nlabels = vispam_datasets['train']['label']\nclass_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\nclass_weights = torch.tensor(class_weights, dtype=torch.float)\n\nspam_only_dataset = vispam_datasets['train'].filter(lambda x: x['spam_label'] != 0)\nspam_labels_filtered = spam_only_dataset['spam_label']\nnew_spam_weights = class_weight.compute_class_weight(\n    class_weight='balanced', \n    classes=np.unique(spam_labels_filtered), \n    y=spam_labels_filtered\n)\n\nspam_class_weights = torch.tensor(new_spam_weights, dtype=torch.float)\n\nclass_weights, spam_class_weights\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\ndef plot_learning_curve(history, task_name=\"Task\"):\n    \"\"\"\n    Plots the Training vs Validation Learning Curve.\n    \n    Args:\n        history (dict): Dictionary containing 'train_loss', 'val_loss', \n                        'train_acc', and 'val_acc'.\n        task_name (str): Title prefix (e.g., \"Task 1 - Spam Detection\")\n    \"\"\"\n    # Use a clean style\n    sns.set(style='whitegrid')\n    \n    # Create a figure with 2 subplots (Loss and Accuracy)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n    \n    epochs = range(1, len(history['train_loss']) + 1)\n    \n    # --- Plot 1: Loss ---\n    ax1.plot(epochs, history['train_loss'], 'b-o', label='Training Loss', linewidth=2)\n    ax1.plot(epochs, history['val_loss'], 'r-o', label='Validation Loss', linewidth=2)\n    ax1.set_title(f'{task_name}: Loss', fontsize=16)\n    ax1.set_xlabel('Epochs', fontsize=14)\n    ax1.set_ylabel('Loss', fontsize=14)\n    ax1.legend(fontsize=12)\n    \n    # --- Plot 2: Accuracy ---\n    if 'train_acc' in history and 'val_acc' in history:\n        ax2.plot(epochs, history['train_acc'], 'b-o', label='Training Accuracy', linewidth=2)\n        ax2.plot(epochs, history['val_acc'], 'r-o', label='Validation Accuracy', linewidth=2)\n        ax2.set_title(f'{task_name}: Accuracy', fontsize=16)\n        ax2.set_xlabel('Epochs', fontsize=14)\n        ax2.set_ylabel('Accuracy', fontsize=14)\n        ax2.legend(fontsize=12)\n        \n        # Set y-axis to always show 0-1 range if it's accuracy\n        # ax2.set_ylim([0, 1.05]) \n    else:\n        ax2.text(0.5, 0.5, 'Accuracy not found in history', \n                 horizontalalignment='center', verticalalignment='center')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- INSERT NEW CELL ---\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha # Class weights\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        # inputs: [N, C], targets: [N]\n        CE_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n        pt = torch.exp(-CE_loss) # Prevents nans\n        F_loss = (1 - pt) ** self.gamma * CE_loss\n\n        if self.reduction == 'mean':\n            return torch.mean(F_loss)\n        elif self.reduction == 'sum':\n            return torch.sum(F_loss)\n        else:\n            return F_loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom tqdm.notebook import tqdm\nimport numpy as np\n\ndef ensemble_predict_custom(model1, model2, dataloader, task, w1=0.5, w2=0.5, threshold=None):\n    \"\"\"\n    H√†m Ensemble ƒë√£ s·ª≠a l·ªói \"Tr·ª´ 1 hai l·∫ßn\".\n    Lu√¥n s·ª≠ d·ª•ng c·ªôt 'label' (0, 1, 2) cho Task 2.\n    \"\"\"\n    model1.eval()\n    model2.eval()\n    \n    all_preds = []\n    all_labels = []\n    \n    device = next(model1.parameters()).device\n    \n    with torch.no_grad():\n        for data in tqdm(dataloader, desc=f\"Ensemble Task {task}\"):\n            input_ids = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            \n            # --- FIX: LU√îN D√ôNG 'label' ---\n            # DataLoader chu·∫©n lu√¥n c√≥ c·ªôt 'label' ƒë√∫ng format (0, 1, 2)\n            # Kh√¥ng t·ª± √Ω tr·ª´ spam_label n·ªØa ƒë·ªÉ tr√°nh l·ªói nh√£n -1\n            if 'label' in data:\n                labels = data['label'].to(device)\n            else:\n                # Fallback ch·ªâ khi kh√¥ng c√≥ 'label' m·ªõi d√πng spam_label\n                labels = data['spam_label'].to(device) - 1\n\n            # X·ª≠ l√Ω Description\n            if 'encoded_description_2' in data: # ∆Øu ti√™n desc 2 cho task 2\n                desc = data['encoded_description_2'].to(device)\n            elif 'encoded_description_1' in data:\n                desc = data['encoded_description_1'].to(device)\n            else:\n                desc = data['encoded_description'].to(device)\n\n            # D·ª± ƒëo√°n\n            logits1 = model1(input_ids, attention_mask, desc)\n            logits2 = model2(input_ids, attention_mask, desc)\n            \n            prob1 = F.softmax(logits1, dim=1)\n            prob2 = F.softmax(logits2, dim=1)\n            \n            final_prob = (w1 * prob1) + (w2 * prob2)\n            \n            if task == 1:\n                if threshold is not None:\n                    spam_prob = final_prob[:, 1]\n                    final_pred = (spam_prob >= threshold).long()\n                else:\n                    final_pred = torch.argmax(final_prob, dim=1)\n            else:\n                # Task 2: Multi-class (0, 1, 2)\n                final_pred = torch.argmax(final_prob, dim=1)\n            \n            all_preds.extend(final_pred.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            \n    return all_labels, all_preds","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_all_probs(model, dataloader):\n    \"\"\"H√†m l·∫•y x√°c su·∫•t c·ªßa to√†n b·ªô t·∫≠p d·ªØ li·ªáu (ƒê√£ fix l·ªói key)\"\"\"\n    model.eval()\n    all_probs = []\n    all_labels = []\n    \n    device = next(model.parameters()).device\n    \n    with torch.no_grad():\n        for data in tqdm(dataloader, desc=f\"Getting probs for {model.model_name}\"):\n            input_ids = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            \n            # --- FIX QUAN TR·ªåNG T·∫†I ƒê√ÇY ---\n            # Ki·ªÉm tra ∆∞u ti√™n key Task 2 -> Task 1 -> Default\n            if 'encoded_description_2' in data:\n                desc = data['encoded_description_2'].to(device)\n            elif 'encoded_description_1' in data:\n                desc = data['encoded_description_1'].to(device)\n            else:\n                desc = data['encoded_description'].to(device)\n                \n            labels = data['label'].to(device)\n            \n            outputs = model(input_ids, attention_mask, desc)\n            probs = F.softmax(outputs, dim=1) # Chuy·ªÉn th√†nh x√°c su·∫•t\n            \n            all_probs.append(probs.cpu().numpy())\n            all_labels.append(labels.cpu().numpy())\n            \n    return np.concatenate(all_probs), np.concatenate(all_labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PhoBERT-MLM-CNN-LSTM","metadata":{}},{"cell_type":"code","source":"        import torch\n        from transformers import AutoTokenizer, AutoModel\n        \n        tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n        model = AutoModel.from_pretrained(\"vinai/phobert-base-v2\").to(\"cuda\") # Chuy·ªÉn l√™n GPU\n        \n        def encode_description(batch):\n            texts = batch[\"clean_description\"]\n            # X·ª≠ l√Ω d·ªØ li·ªáu tr·ªëng\n            texts = [str(t) if t is not None else \"\" for t in texts]\n            segmented_texts = [segment_text(t) for t in texts]\n        \n            # 2. Tokenize to√†n b·ªô batch\n            inputs = tokenizer(\n                segmented_texts, \n                padding=True, \n                truncation=True, \n                max_length=256, \n                return_tensors='pt'\n            ).to(\"cuda\")\n        \n            # 3. Ch·∫°y qua Model ƒë·ªÉ l·∫•y hidden states\n            with torch.no_grad():\n                outputs = model(**inputs)\n        \n            # 4. Mean Pooling: T√≠nh trung b√¨nh c·ªông c√°c token ƒë·ªÉ ra vector ƒë·∫°i di·ªán cho c√¢u\n            # L·∫•y layer cu·ªëi c√πng (last_hidden_state)\n            token_embeddings = outputs.last_hidden_state\n            mask = inputs['attention_mask'].unsqueeze(-1).expand(token_embeddings.size()).float()\n            \n            sum_embeddings = torch.sum(token_embeddings * mask, 1)\n            sum_mask = torch.clamp(mask.sum(1), min=1e-9)\n            \n            # K·∫øt qu·∫£ l√† vector embedding (th∆∞·ªùng c√≥ k√≠ch th∆∞·ªõc 768)\n            embeddings = (sum_embeddings / sum_mask).cpu().numpy()\n        \n            # Tr·∫£ v·ªÅ k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng list ƒë·ªÉ map v√†o dataset\n            return {\n                \"encoded_description_1\": embeddings.tolist(),\n                \"encoded_description_2\": embeddings.tolist()\n            }\n        \n        # 5. Ch·∫°y Map v·ªõi batch_size ph√π h·ª£p\n        vispam_datasets = vispam_datasets.map(\n            encode_description,\n            batched=True,\n            batch_size=32 # Gi·∫£m xu·ªëng 32 ƒë·ªÉ tr√°nh l·ªói CUDA out of memory tr√™n Kaggle\n        )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n\ndef encode_comment(examples):\n    # Get the raw text\n    raw_texts = examples[\"clean_tokenized_comment\"]\n    \n    # NEW: Apply segmentation first!\n    segmented_texts = [segment_text(t) for t in raw_texts]\n    \n    return tokenizer(\n        segmented_texts, \n        padding=\"max_length\", \n        max_length=100, \n        truncation=True, \n        add_special_tokens=True\n    )\n\nencoded_datasets = vispam_datasets.map(encode_comment, batched=True)\nencoded_datasets = encoded_datasets.remove_columns(vispam_datasets['train'].column_names[:-4])\nencoded_datasets.set_format(\"torch\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ndef filter_spam_only(example):\n    return example['spam_label'] != 0\n\n\ndef map_labels_to_zero_index(example):\n    example['spam_label'] = example['spam_label'] - 1 \n    return example\n\n\ntrain_dataloader = DataLoader(encoded_datasets['train'], shuffle=True, batch_size=16)\nval_dataloader = DataLoader(encoded_datasets['dev'], batch_size=16)\ntest_dataloader = DataLoader(encoded_datasets['test'], batch_size=16)\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Task 1","metadata":{}},{"cell_type":"code","source":"from torch import nn\nimport torch.optim as optim  \nfrom torch.optim import AdamW \nfrom transformers import get_linear_schedule_with_warmup\n\n\nmodel = ViSpam_Classifier_PhoBertBiLSTM(task=1, drop=0.3).to(device)\nbert_params = list(map(id, model.bert.parameters()))\nbase_params = filter(lambda p: id(p) not in bert_params, model.parameters())\n\noptimizer = AdamW([\n    {'params': model.bert.parameters(), 'lr': 1e-5}, \n    {'params': base_params, 'lr': 5e-4}            \n], weight_decay=0.01)\n\ncriterion = FocalLoss(alpha=class_weights.to(device), gamma=3.0, reduction='mean')\nepochs = 20\nlr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader)*epochs)\nearly_stopping = EarlyStopping(patience=4, delta=0)\nhistory_task1_LSTM = train(model, criterion, optimizer, train_dataloader, val_dataloader, epochs, early_stopping, task=1)\n\n\nmodel = ViSpam_Classifier_PhoBertCNN(task=1, drop=0.3).to(device)\nbert_params = list(map(id, model.bert.parameters()))\nbase_params = filter(lambda p: id(p) not in bert_params, model.parameters())\n\noptimizer = AdamW([\n    {'params': model.bert.parameters(), 'lr': 1e-5}, \n    {'params': base_params, 'lr': 5e-4}            \n], weight_decay=0.01)\n\ncriterion = FocalLoss(alpha=class_weights.to(device), gamma=3.0, reduction='mean')\nepochs = 20\nlr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader)*epochs)\nearly_stopping = EarlyStopping(patience=4, delta=0)\nhistory_task1_CNN = train(model, criterion, optimizer, train_dataloader, val_dataloader, epochs, early_stopping, task=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model 1: CNN (Chuy√™n b·∫Øt Precision - √çt ƒëo√°n nh·∫ßm)\nmodel_cnn = ViSpam_Classifier_PhoBertCNN(task=1, drop=0.3).to(device)\npath_cnn = 'ngcanh/finetunephobert/PhoBert-CNN/PhoBert-CNN_best_model_(1).pth'\n\n# Model 2: BiLSTM (Chuy√™n b·∫Øt Recall - B·∫Øt ƒë∆∞·ª£c nhi·ªÅu spam kh√≥)\nmodel_lstm = ViSpam_Classifier_PhoBertBiLSTM(task=1, drop=0.3).to(device)\npath_lstm = 'ngcanh/finetunephobert/PhoBert-BiLSTM/PhoBert-BiLSTM_best_model_(1).pth'\n\n\n\n# Load tr·ªçng s·ªë ƒë√£ train\nif os.path.exists(path_cnn) and os.path.exists(path_lstm):\n    print(\"Loading models...\")\n    model_cnn.load_state_dict(torch.load(path_cnn))\n    model_lstm.load_state_dict(torch.load(path_lstm))\n    model_cnn.eval()\n    model_lstm.eval()\n    print(\"Models loaded successfully!\")\nelse:\n    print(\"Error: Checkpoint files not found. Please check paths.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_visualization_history(history_task1_LSTM, 'PhoBert-BiLSTM', task=1)\nplotting_history(history_task1_LSTM)\nsave_visualization_history(history_task1_CNN, 'PhoBert-CNN', task=1)\nplotting_history(history_task1_CNN)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom tqdm import tqdm\n\n# 1. L·∫•y x√°c su·∫•t g·ªëc t·ª´ 2 model (Ch·ªâ ch·∫°y 1 l·∫ßn t·ªën th·ªùi gian)\nprint(\"ƒêang l·∫•y d·ªØ li·ªáu t·ª´ CNN...\")\nprobs_cnn, y_true = get_all_probs(model_cnn, test_dataloader)\n\nprint(\"ƒêang l·∫•y d·ªØ li·ªáu t·ª´ BiLSTM...\")\nprobs_lstm, _ = get_all_probs(model_lstm, test_dataloader)\n\n# 2. Thu·∫≠t to√°n t√¨m Weight v√† Threshold t·ªëi ∆∞u\nprint(\"\\nƒêang t√¨m tham s·ªë t·ªëi ∆∞u...\")\nbest_acc = 0\nbest_f1 = 0\nbest_config_1 = {}\n\n# Th·ª≠ c√°c tr·ªçng s·ªë cho CNN t·ª´ 0.0 ƒë·∫øn 1.0 (b∆∞·ªõc nh·∫£y 0.05)\nfor w_cnn in np.arange(0.0, 1.05, 0.02):\n    w_lstm = 1.0 - w_cnn\n    \n    # T√≠nh x√°c su·∫•t g·ªôp\n    # shape: [N_samples, 2]\n    ensemble_prob = (w_cnn * probs_cnn) + (w_lstm * probs_lstm)\n    \n    # Ch·ªâ quan t√¢m x√°c su·∫•t l·ªõp Spam (c·ªôt 1)\n    spam_prob = ensemble_prob[:, 1]\n    \n    # Th·ª≠ c√°c ng∆∞·ª°ng t·ª´ 0.3 ƒë·∫øn 0.7\n    for threshold in np.arange(0.3, 0.9, 0.02):\n        # D·ª± ƒëo√°n: n·∫øu x√°c su·∫•t spam > threshold th√¨ l√† 1, ng∆∞·ª£c l·∫°i 0\n        y_pred = (spam_prob > threshold).astype(int)\n        \n        acc = accuracy_score(y_true, y_pred)\n        f1 = f1_score(y_true, y_pred, average='macro')\n        \n        # L∆∞u k·∫øt qu·∫£ t·ªët nh·∫•t (∆∞u ti√™n Accuracy)\n        if acc > best_acc:\n            best_acc = acc\n            best_f1 = f1\n            best_config_1 = {\n                'w_cnn': w_cnn,\n                'w_lstm': w_lstm,\n                'threshold': threshold\n            }\n\nprint(\"-\" * 30)\nprint(f\"üèÜ C·∫§U H√åNH T·ªêT NH·∫§T T√åM ƒê∆Ø·ª¢C:\")\nprint(f\"   ‚ñ∫ Tr·ªçng s·ªë CNN: {best_config_1['w_cnn']:.2f}\")\nprint(f\"   ‚ñ∫ Tr·ªçng s·ªë LSTM: {best_config_1['w_lstm']:.2f}\")\nprint(f\"   ‚ñ∫ Ng∆∞·ª°ng (Threshold): {best_config_1['threshold']:.2f}\")\nprint(f\"   ---------------------------\")\nprint(f\"   üî• MAX ACCURACY: {best_acc:.4f}\")\nprint(f\"   üî• MAX F1-SCORE: {best_f1:.4f}\")\nprint(\"-\" * 30)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport numpy as np\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# Ch·∫°y Ensemble tr√™n t·∫≠p Test\n# w1=0.6 (CNN), w2=0.4 (LSTM) l√† t·ª∑ l·ªá khuy·∫øn ngh·ªã ban ƒë·∫ßu\n# true_labels, ensemble_preds = ensemble_predict_custom(model_cnn, model_lstm, test_dataloader, task=1, w1=0.64, w2=0.36, threshold=0.7)\ntrue_labels, ensemble_preds = ensemble_predict_custom(model_cnn, model_lstm, test_dataloader, task=1, w1=best_config_1['w_cnn'], w2=best_config_1['w_lstm'], threshold=best_config_1['threshold'])\n\n# Hi·ªÉn th·ªã k·∫øt qu·∫£\nprint(\"\\n=== K·∫æT QU·∫¢ SAU KHI ENSEMBLE ===\")\ncm = evaluate(true_labels, ensemble_preds) # H√†m evaluate c≈© c·ªßa b·∫°n\n\nplotting_confusion_matrix(cm, task=1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Task 2","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom sklearn.utils import class_weight\nfrom torch.utils.data import DataLoader\n\n# --- 1. H√†m chu·∫©n b·ªã Dataloader chu·∫©n cho Task 2 ---\ndef prepare_task2_data(dataset, batch_size=16, is_train=False):\n    # L·ªçc ch·ªâ l·∫•y Spam (spam_label 1, 2, 3)\n    ds = dataset.filter(lambda x: x['spam_label'] != 0)\n    \n    # Map nh√£n: 1->0, 2->1, 3->2\n    def map_labels(example):\n        example['label'] = example['spam_label'] - 1 \n        return example\n    \n    ds = ds.map(map_labels)\n    \n    # Set format ƒë·ªÉ PyTorch nh·∫≠n di·ªán ƒë√∫ng c·ªôt Tensor\n    cols = ['input_ids', 'attention_mask', 'encoded_description_2', 'label']\n    ds.set_format(type='torch', columns=cols)\n    \n    return DataLoader(ds, batch_size=batch_size, shuffle=is_train)\n\n# T·∫°o Dataloader\nprint(\"‚è≥ ƒêang t·∫°o Dataloader cho Task 2...\")\ntrain_dataloader_2 = prepare_task2_data(encoded_datasets['train'], batch_size=16, is_train=True)\nval_dataloader_2 = prepare_task2_data(encoded_datasets['dev'], batch_size=16, is_train=False)\ntest_dataloader_2 = prepare_task2_data(encoded_datasets['test'], batch_size=16, is_train=False)\n\n# --- 2. T√≠nh Spam Class Weights (ƒê√É S·ª¨A L·ªñI) ---\nprint(\"‚öñÔ∏è ƒêang t√≠nh Class Weights cho 3 lo·∫°i Spam...\")\n\n# FIX: Chuy·ªÉn sang Numpy Array ngay l·∫≠p t·ª©c ƒë·ªÉ x·ª≠ l√Ω\nall_labels = np.array(encoded_datasets['train']['spam_label'])\n\n# L·ªçc b·ªè s·ªë 0 (Non-spam) b·∫±ng Numpy\nspam_labels_numpy = all_labels[all_labels != 0]\n\n# Tr·ª´ 1 ƒë·ªÉ v·ªÅ nh√£n 0, 1, 2\nspam_train_labels = spam_labels_numpy - 1\n\n# T√≠nh weight\nweights = class_weight.compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(spam_train_labels),\n    y=spam_train_labels\n)\n\n# Chuy·ªÉn weights sang Tensor v√† ƒë∆∞a v√†o Device\nspam_class_weights = torch.tensor(weights, dtype=torch.float).to(device)\n\nprint(\"‚úÖ Ho√†n t·∫•t! Weights:\", spam_class_weights)\nprint(\"‚úÖ S·∫µn s√†ng train.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.optim import AdamW \nfrom transformers import get_linear_schedule_with_warmup\n\n# --- 1. S·ª≠a ƒëo·∫°n BiLSTM ---\n# L∆ØU √ù: ƒê·ªïi task=1 th√†nh task=2\nmodel = ViSpam_Classifier_PhoBertBiLSTM(task=2, drop=0.3).to(device)\n\nbert_params = list(map(id, model.bert.parameters()))\nbase_params = filter(lambda p: id(p) not in bert_params, model.parameters())\n\noptimizer = AdamW([\n    {'params': model.bert.parameters(), 'lr': 1e-5}, \n    {'params': base_params, 'lr': 5e-4}            \n], weight_decay=0.01)\n\n# L∆ØU √ù: Ph·∫£i d√πng weights c·ªßa Task 2 (spam_class_weights)\n# N·∫øu b·∫°n ch∆∞a t√≠nh, h√£y d√πng None t·∫°m th·ªùi ho·∫∑c t√≠nh l·∫°i weights cho 3 class spam\ncriterion = FocalLoss(alpha=spam_class_weights.to(device), gamma=3.0, reduction='mean')\n\nepochs = 20\nlr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader_2)*epochs)\nearly_stopping = EarlyStopping(patience=5, delta=0)\n\n# Ch·∫°y train\nhistory_task2_LSTM = train(model, criterion, optimizer, train_dataloader_2, val_dataloader_2, epochs, early_stopping, task=2)\n\n\n# --- 2. S·ª≠a ƒëo·∫°n CNN ---\n# ƒêo·∫°n n√†y b·∫°n ƒë√£ ƒë·ªÉ task=2 l√† ƒë√∫ng, nh∆∞ng c·∫ßn s·ª≠a class_weights\nmodel = ViSpam_Classifier_PhoBertCNN(task=2, drop=0.3).to(device)\n\nbert_params = list(map(id, model.bert.parameters()))\nbase_params = filter(lambda p: id(p) not in bert_params, model.parameters())\n\noptimizer = AdamW([\n    {'params': model.bert.parameters(), 'lr': 1e-5}, \n    {'params': base_params, 'lr': 5e-4}            \n], weight_decay=0.01)\n\n# L∆ØU √ù: S·ª≠a class_weights th√†nh spam_class_weights\ncriterion = FocalLoss(alpha=spam_class_weights.to(device), gamma=3.0, reduction='mean')\n\nepochs = 20\nlr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader_2)*epochs)\nearly_stopping = EarlyStopping(patience=5, delta=0)\n\nhistory_task2_CNN = train(model, criterion, optimizer, train_dataloader_2, val_dataloader_2, epochs, early_stopping, task=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport numpy as np\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Model 1: CNN (Chuy√™n b·∫Øt Precision - √çt ƒëo√°n nh·∫ßm)\nmodel_cnn = ViSpam_Classifier_PhoBertCNN(task=2, drop=0.3).to(device)\npath_cnn = 'ngcanh/finetunephobert/PhoBert-CNN/PhoBert-CNN_best_model_(2).pth'\n\n# Model 2: BiLSTM (Chuy√™n b·∫Øt Recall - B·∫Øt ƒë∆∞·ª£c nhi·ªÅu spam kh√≥)\nmodel_lstm = ViSpam_Classifier_PhoBertBiLSTM(task=2, drop=0.3).to(device)\npath_lstm = 'ngcanh/finetunephobert/PhoBert-BiLSTM/PhoBert-BiLSTM_best_model_(2).pth'\n\n# Load tr·ªçng s·ªë ƒë√£ train\nif os.path.exists(path_cnn) and os.path.exists(path_lstm):\n    print(\"Loading models...\")\n    model_cnn.load_state_dict(torch.load(path_cnn))\n    model_lstm.load_state_dict(torch.load(path_lstm))\n    model_cnn.eval()\n    model_lstm.eval()\n    print(\"Models loaded successfully!\")\nelse:\n    print(\"Error: Checkpoint files not found. Please check paths.\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom tqdm import tqdm\n\n\n# 1. L·∫•y x√°c su·∫•t g·ªëc t·ª´ 2 model (Ch·ªâ ch·∫°y 1 l·∫ßn t·ªën th·ªùi gian)\nprint(\"ƒêang l·∫•y d·ªØ li·ªáu t·ª´ CNN...\")\nprobs_cnn, y_true = get_all_probs(model_cnn, test_dataloader_2)\n\nprint(\"ƒêang l·∫•y d·ªØ li·ªáu t·ª´ BiLSTM...\")\nprobs_lstm, _ = get_all_probs(model_lstm, test_dataloader_2)\n\n# 2. Thu·∫≠t to√°n t√¨m Weight t·ªëi ∆∞u cho Multi-class (Task 2)\nprint(\"\\nƒêang t√¨m tham s·ªë t·ªëi ∆∞u cho Task 2 (Multi-class)...\")\nbest_acc = 0\nbest_f1 = 0\nbest_config_2 = {}\n\n# Th·ª≠ c√°c tr·ªçng s·ªë cho CNN t·ª´ 0.0 ƒë·∫øn 1.0 (b∆∞·ªõc nh·∫£y 0.05)\nfor w_cnn in np.arange(0.0, 1.05, 0.02):\n    w_lstm = 1.0 - w_cnn\n    \n    # T√≠nh x√°c su·∫•t g·ªôp\n    # shape: [N_samples, 3] (V√¨ l√† task 2)\n    ensemble_prob = (w_cnn * probs_cnn) + (w_lstm * probs_lstm)\n    \n    # --- FIX QUAN TR·ªåNG: D√πng Argmax thay v√¨ Threshold ---\n    # Ch·ªçn l·ªõp c√≥ x√°c su·∫•t cao nh·∫•t trong 3 l·ªõp (0, 1, 2)\n    y_pred = np.argmax(ensemble_prob, axis=1)\n    \n    acc = accuracy_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred, average='macro')\n    \n    # L∆∞u k·∫øt qu·∫£ t·ªët nh·∫•t (∆Øu ti√™n F1-macro cho Task 2 ƒë·ªÉ ƒë·∫£m b·∫£o c√°c l·ªõp ƒë·ªÅu t·ªët)\n    if f1 > best_f1:\n        best_acc = acc\n        best_f1 = f1\n        best_config_2 = {\n            'w_cnn': w_cnn,\n            'w_lstm': w_lstm\n        }\n\nprint(\"-\" * 30)\nprint(f\"üèÜ C·∫§U H√åNH T·ªêT NH·∫§T T√åM ƒê∆Ø·ª¢C (TASK 2):\")\nprint(f\"   ‚ñ∫ Tr·ªçng s·ªë CNN: {best_config_2['w_cnn']:.2f}\")\nprint(f\"   ‚ñ∫ Tr·ªçng s·ªë LSTM: {best_config_2['w_lstm']:.2f}\")\nprint(f\"   ---------------------------\")\nprint(f\"   üî• MAX ACCURACY: {best_acc:.4f}\")\nprint(f\"   üî• MAX F1-MACRO: {best_f1:.4f}\")\nprint(\"-\" * 30)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ch·∫°y Ensemble tr√™n t·∫≠p Test\ntrue_labels, ensemble_preds = ensemble_predict_custom(model_cnn, model_lstm, test_dataloader_2, task=2, w1=best_config_2['w_cnn'], w2=best_config_2['w_lstm'])\n\n# Hi·ªÉn th·ªã k·∫øt qu·∫£\nprint(\"\\n=== K·∫æT QU·∫¢ SAU KHI ENSEMBLE ===\")\ntest_cm = evaluate(true_labels, ensemble_preds) # H√†m evaluate c≈© c·ªßa b·∫°n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plotting_confusion_matrix(test_cm, task=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_visualization_history(history_task2_LSTM, 'PhoBert-BiLSTM', task=2)\nplotting_history(history_task2_LSTM)\nsave_visualization_history(history_task2_CNN, 'PhoBert-CNN', task=2)\nplotting_history(history_task2_CNN)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## PIPELINE ( TASK 1 -> TASK 2)","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef evaluate_pipeline(true_labels, predicts):\n    # T√≠nh to√°n c√°c ch·ªâ s·ªë\n    test_accuracy = accuracy_score(true_labels, predicts)\n    test_f1 = f1_score(true_labels, predicts, average='macro')\n    test_cm = confusion_matrix(true_labels, predicts)\n    \n    print(\"=\"*30)\n    print(\"   PIPELINE EVALUATION RESULTS   \")\n    print(\"=\"*30)\n    print(f\"‚úÖ Accuracy: {test_accuracy:.4f}\")\n    print(f\"‚úÖ F1-Macro: {test_f1:.4f}\")\n    print(\"-\" * 30)\n    \n    # Classification Report chi ti·∫øt cho 4 nh√£n\n    target_names = ['Non-Spam (0)', 'Spam Type 1', 'Spam Type 2', 'Spam Type 3']\n    \n    # Ki·ªÉm tra xem t·∫≠p test c√≥ ƒë·ªß 4 nh√£n kh√¥ng ƒë·ªÉ tr√°nh l·ªói in report\n    unique_labels = sorted(list(set(true_labels) | set(predicts)))\n    present_names = [target_names[i] for i in unique_labels]\n    \n    print(classification_report(true_labels, predicts, target_names=present_names, digits=4))\n    \n    # V·∫Ω Confusion Matrix\n    plt.figure(figsize=(8, 6))\n    df_cm = pd.DataFrame(test_cm, index=present_names, columns=present_names)\n    sns.heatmap(df_cm, annot=True, cmap=\"Blues\", fmt=\"g\", cbar=True)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Pipeline Confusion Matrix\")\n    plt.show()\n    \n    return test_cm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom tqdm.notebook import tqdm\nimport numpy as np\n\ndef test_pipeline_ensemble(\n    models_task1,  # List [model_cnn_1, model_lstm_1]\n    models_task2,  # List [model_cnn_2, model_lstm_2]\n    dataloader, \n    device,\n    weights_task1=(0.6, 0.4), # Tr·ªçng s·ªë (CNN, LSTM) cho Task 1\n    weights_task2=(0.5, 0.5), # Tr·ªçng s·ªë cho Task 2\n    threshold_task1=0.7       # Ng∆∞·ª°ng spam cho Task 1\n):\n    \"\"\"\n    Pipeline Full Ensemble:\n    1. Input -> Ensemble Task 1 (CNN+LSTM) -> Binary Pred\n    2. If Spam -> Ensemble Task 2 (CNN+LSTM) -> Type Pred\n    \"\"\"\n    # Chuy·ªÉn t·∫•t c·∫£ model sang eval\n    for m in models_task1 + models_task2:\n        m.eval()\n        \n    all_predicts = []\n    all_true_labels = []\n    \n    print(\"üöÄ Running Ensemble Pipeline Testing...\")\n    \n    with torch.no_grad():\n        for data in tqdm(dataloader, desc=\"Pipeline Ensemble\"):\n            input_ids = data['input_ids'].to(device)\n            attention_mask = data['attention_mask'].to(device)\n            \n            # L·∫•y Ground Truth (∆∞u ti√™n spam_label n·∫øu c√≥)\n            if 'spam_label' in data:\n                labels = data['spam_label'].to(device)\n            else:\n                labels = data['label'].to(device)\n\n            # ---------------------------------------------\n            # B∆Ø·ªöC 1: ENSEMBLE TASK 1 (BINARY)\n            # ---------------------------------------------\n            # L·∫•y Description Task 1\n            if 'encoded_description_1' in data:\n                desc1 = data['encoded_description_1'].to(device)\n            else:\n                desc1 = data['encoded_description'].to(device)\n\n            # Model 1 (CNN)\n            out1_cnn = models_task1[0](input_ids, attention_mask, desc1)\n            prob1_cnn = F.softmax(out1_cnn, dim=1)\n            \n            # Model 2 (LSTM)\n            out1_lstm = models_task1[1](input_ids, attention_mask, desc1)\n            prob1_lstm = F.softmax(out1_lstm, dim=1)\n            \n            # Ensemble Prob\n            final_prob1 = (weights_task1[0] * prob1_cnn) + (weights_task1[1] * prob1_lstm)\n            \n            # Binary Prediction (d·ª±a tr√™n Threshold)\n            spam_prob = final_prob1[:, 1]\n            pred1 = (spam_prob >= threshold_task1).long()\n            \n            # M·∫∑c ƒë·ªãnh d·ª± ƒëo√°n l√† 0 (ho·∫∑c 1 t√πy pred1), ta clone ra ƒë·ªÉ s·ª≠a nh·ªØng m·∫´u l√† spam\n            final_batch_preds = pred1.clone()\n\n            # ---------------------------------------------\n            # B∆Ø·ªöC 2: ENSEMBLE TASK 2 (MULTI-CLASS)\n            # ---------------------------------------------\n            # Ch·ªâ l·∫•y c√°c m·∫´u ƒë∆∞·ª£c d·ª± ƒëo√°n l√† Spam\n            spam_indices = torch.nonzero(pred1 == 1).squeeze()\n            \n            if spam_indices.numel() > 0:\n                if spam_indices.dim() == 0: spam_indices = spam_indices.unsqueeze(0)\n                \n                # L·ªçc input\n                sub_input = input_ids[spam_indices]\n                sub_mask = attention_mask[spam_indices]\n                \n                # L·∫•y Description Task 2\n                if 'encoded_description_2' in data:\n                    sub_desc2 = data['encoded_description_2'].to(device)[spam_indices]\n                else:\n                    sub_desc2 = data['encoded_description'].to(device)[spam_indices]\n                \n                # Model 1 Task 2 (CNN)\n                out2_cnn = models_task2[0](sub_input, sub_mask, sub_desc2)\n                prob2_cnn = F.softmax(out2_cnn, dim=1)\n                \n                # Model 2 Task 2 (LSTM)\n                out2_lstm = models_task2[1](sub_input, sub_mask, sub_desc2)\n                prob2_lstm = F.softmax(out2_lstm, dim=1)\n                \n                # Ensemble Prob Task 2\n                final_prob2 = (weights_task2[0] * prob2_cnn) + (weights_task2[1] * prob2_lstm)\n                \n                # Ch·ªçn nh√£n (0,1,2) -> C·ªông 1 ƒë·ªÉ th√†nh (1,2,3)\n                pred2_raw = torch.argmax(final_prob2, dim=1)\n                pred2_real = pred2_raw + 1\n                \n                # C·∫≠p nh·∫≠t v√†o k·∫øt qu·∫£\n                final_batch_preds[spam_indices] = pred2_real\n            \n            all_predicts.extend(final_batch_preds.cpu().numpy())\n            all_true_labels.extend(labels.cpu().numpy())\n\n    return all_true_labels, all_predicts","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 1. Load Models Task 1 (Binary) ---\nprint(\"Loading Task 1 Models...\")\nt1_cnn = ViSpam_Classifier_PhoBertCNN(task=1).to(device)\nt1_cnn.load_state_dict(torch.load('ngcanh/finetunephobert/PhoBert-CNN/PhoBert-CNN_best_model_(1).pth'))\n\nt1_lstm = ViSpam_Classifier_PhoBertBiLSTM(task=1).to(device)\nt1_lstm.load_state_dict(torch.load('ngcanh/finetunephobert/PhoBert-BiLSTM/PhoBert-BiLSTM_best_model_(1).pth'))\n\n\n# --- 2. Load Models Task 2 (Spam Type) ---\nprint(\"Loading Task 2 Models...\")\nt2_cnn = ViSpam_Classifier_PhoBertCNN(task=2).to(device)\nt2_cnn.load_state_dict(torch.load('ngcanh/finetunephobert/PhoBert-CNN/PhoBert-CNN_best_model_(2).pth'))\n\nt2_lstm = ViSpam_Classifier_PhoBertBiLSTM(task=2).to(device)\nt2_lstm.load_state_dict(torch.load('ngcanh/finetunephobert/PhoBert-BiLSTM/PhoBert-BiLSTM_best_model_(2).pth'))\n\n\n# --- 3. Ch·∫°y Pipeline Ensemble ---\n# D√πng test_dataloader (ch·ª©a ƒë·∫ßy ƒë·ªß d·ªØ li·ªáu)\nprint(\"Running Full Ensemble Pipeline...\")\n\ntrue_labels, final_preds = test_pipeline_ensemble(\n    models_task1=[t1_cnn, t1_lstm],\n    models_task2=[t2_cnn, t2_lstm],\n    dataloader=test_dataloader,\n    device=device,\n    weights_task1=(0.6, 0.4), # T√πy ch·ªânh theo k·∫øt qu·∫£ t·ªët nh·∫•t b·∫°n t√¨m ƒë∆∞·ª£c ·ªü Task 1\n    weights_task2=(0.5, 0.5), # T√πy ch·ªânh theo Task 2\n    threshold_task1=0.7       # Ng∆∞·ª°ng Binary\n)\n\n# --- 4. ƒê√°nh gi√° ---\nevaluate_pipeline(true_labels, final_preds)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}